{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport tensorflow as tf \nfrom tensorflow import keras \nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import precision_recall_curve, roc_curve, accuracy_score, confusion_matrix, precision_score, recall_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt \nimport seaborn as sns \nplt.style.use('fivethirtyeight')\nimport pickle \nimport os \nimport numpy as np\nimport cv2 \n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Process the images and resize them to the preferred size </h2>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"labels = ['PNEUMONIA', 'NORMAL']\nimg_size = 200\ndef get_training_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Preparing the training and testing data</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/train')\ntest = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/test')\nval = get_training_data('../input/chest-xray-pneumonia/chest_xray/chest_xray/val')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pnenumonia = 0 \nnormal = 0 \n\nfor i, j in train:\n    if j == 0:\n        pnenumonia+=1\n    else:\n        normal+=1\n        \nprint('Pneumonia:', pnenumonia)\nprint('Normal:', normal)\nprint('Pneumonia - Normal:', pnenumonia-normal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Visualize training images</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train[1][0], cmap='gray')\nplt.axis('off')\nprint(labels[train[1][1]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 >We are incoprating the validation data into the training data because it does not contain enough examples. </h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\ny = []\n\nfor feature, label in train:\n    X.append(feature)\n    y.append(label)\n\nfor feature, label in test:\n    X.append(feature)\n    y.append(label)\n    \nfor feature, label in val:\n    X.append(feature)\n    y.append(label)\n\n\n# resize data for deep learning \nX = np.array(X).reshape(-1, img_size, img_size, 1)\ny = np.array(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train / 255\nX_test = X_test / 255\nX_val = X_val / 255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data augmentation "},{"metadata":{"trusted":true},"cell_type":"code","source":"# good for balancing out disproportions in the dataset \ndatagen = ImageDataGenerator(\n        featurewise_center=False, \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=90, \n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip=True,  \n        vertical_flip=True)  \n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2 >CNN (Convolutional Neural Network) </h2>\nImage source: https://www.researchgate.net/publication/321286547/figure/download/fig6/AS:564402564472832@1511575465150/A-convolutional-neural-networks-CNN.png"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(256, (3, 3), input_shape=X_train.shape[1:], padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(Conv2D(16, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nmodel.add(BatchNormalization(axis=1))\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n\nmodel.add(Dropout(0.5))\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\n\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nearly_stop = EarlyStopping(patience=3, monitor='val_loss', restore_best_weights=True)\nadam = Adam(learning_rate=0.0001)\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(datagen.flow(X_train, y_train, batch_size=10), callbacks=[early_stop], validation_data=(X_val, y_val), epochs=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Visualizing our training progress</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 9))\nplt.plot(history.epoch, history.history['acc'])\nplt.title('Model Accuracy')\nplt.legend(['train'], loc='upper left')\nplt.show()\n\nplt.figure(figsize=(16, 9))\nplt.plot(history.epoch, history.history['loss'])\nplt.title('Model Loss')\nplt.legend(['train'], loc='upper left')\nplt.show()\n\nplt.figure(figsize=(16, 9))\nplt.plot(history.epoch, history.history['val_acc'])\nplt.title('Model Validation Accuracy')\nplt.legend(['train'], loc='upper left')\nplt.show()\n\nplt.figure(figsize=(16, 9))\nplt.plot(history.epoch, history.history['val_loss'])\nplt.title('Model Validation Loss')\nplt.legend(['train'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Prepare data for precision vs. recall and ROC</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_train)\nprecisions, recalls, thresholds = precision_recall_curve(y_train, pred)\nfpr, tpr, thresholds2 = roc_curve(y_train, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_precision_recall(precisions, recalls, thresholds):\n    plt.plot(thresholds, precisions[:-1], 'b--')\n    plt.plot(thresholds, recalls[:-1], 'g-')\n    plt.title('Precision vs. Recall')\n    plt.xlabel('Thresholds')\n    plt.legend(['Precision', 'Recall'], loc='best')\n    plt.show()\n\ndef plot_roc(fpr, tpr):\n    plt.plot(fpr, tpr)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.title('FPR (False Positive rate) vs TPR (True Positive Rate)')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate (Recall)')\n    plt.show()\n    \nplot_precision_recall(precisions, recalls, thresholds)\nplot_roc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Set thresholds for our model, we want the results to be precise while not sacraficing too much recall </h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"binary_predictions = []\nthreshold = thresholds[np.argmax(precisions >= 0.80)]\nfor i in predictions:\n    if i >= threshold:\n        binary_predictions.append(1)\n    else:\n        binary_predictions.append(0) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))\nprint('Precision on testing set:', precision_score(binary_predictions, y_test))\nprint('Recall on testing set:', recall_score(binary_predictions, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Plotting the confusion matrix. Here is how we interpet one. </h2>\n\nImage source: https://silvrback.s3.amazonaws.com/uploads/4ab81a17-4a77-4e9e-b092-de5fac2afa07/confusionmatrix_large.png"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = confusion_matrix(binary_predictions, y_test)\nplt.figure(figsize=(16, 9))\nax= plt.subplot()\nsns.heatmap(matrix, annot=True, ax = ax)\n\n# labels, title and ticks\nax.set_xlabel('Predicted Labels', size=20)\nax.set_ylabel('True Labels', size=20)\nax.set_title('Confusion Matrix', size=20) \nax.xaxis.set_ticklabels(labels)\nax.yaxis.set_ticklabels(labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>View some results from a sample of 25 images</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train.reshape(-1, img_size, img_size)[i], cmap='gray')\n    if(binary_predictions[i]==y_test[i]):\n        plt.xlabel(labels[binary_predictions[i]], color='blue')\n    else:\n        plt.xlabel(labels[binary_predictions[i]], color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Download the model</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":" model.save('pneumonia_detection_ai_version_3.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Reflection: </h2>\n<h3> There are a lot of rooms to improve. If you have any questions or suggestions, please leave a comment below.</h3>"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}